{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a key for reproducibility\n",
    "key = jax.random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<https://www.tensorflow.org/datasets/api_docs/python/tfds/load>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "# 1150 files\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# tfds works in both Eager and Graph modes\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# Load the full GMD with MIDI only (no audio) as a tf.data.Dataset\n",
    "dataset = tfds.load(\n",
    "    name=\"groove/full-midionly\",\n",
    "    split=tfds.Split.TRAIN,\n",
    "    try_gcs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your input pipeline\n",
    "dataset = dataset.shuffle(1024).batch(32).prefetch(\n",
    "    tf.data.experimental.AUTOTUNE)\n",
    "for features in dataset.take(1):\n",
    "  # Access the features you are interested in\n",
    "  midi, genre = features[\"midi\"], features[\"style\"][\"primary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from mido import MidiFile\n",
    "import mido\n",
    "\n",
    "seed = 42\n",
    "# tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "class DataPoint:\n",
    "    def __init__(self,\n",
    "                 midi_data,\n",
    "                 features,\n",
    "                 audio_file_path,\n",
    "                 midi_file_path,\n",
    "                 purpose) -> None:\n",
    "        self.midi_data = midi_data\n",
    "        self.features = features\n",
    "        self.audio_file_path = audio_file_path\n",
    "        self.midi_file_path = midi_file_path\n",
    "        self.purpose = purpose\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_names = [\"style\", \"bpm\", \"beat_type\", \"time_signature\", \"duration\"]\n",
    "feature_to_column_idx = {\n",
    "    \"session\" : 0,\n",
    "    \"drummer\" : 1,\n",
    "    \"id\" : 2,\n",
    "    \"style\" : 3,\n",
    "    \"bpm\" : 4,\n",
    "    \"beat_type\" : 5,\n",
    "    \"time_signature\" : 6,\n",
    "    \"midi_filename\" : 7,\n",
    "    \"audio_filename\" : 8,\n",
    "    \"duration\" : 9,\n",
    "    \"split\" : 10\n",
    "}\n",
    "\n",
    "def play_audio(midi_data: MidiFile) -> None:\n",
    "    # Create output port for playing samples\n",
    "    with mido.open_output(autoreset=True) as outport: \n",
    "        for msg in midi_data.play():\n",
    "            outport.send(msg)\n",
    "\n",
    "    if not outport.closed:\n",
    "        print(\"Closing port...\")\n",
    "        outport.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drummer1', 'drummer1/eval_session', 'drummer1/eval_session/1', 'funk/groove1', '138', 'beat', '4-4', 'drummer1/eval_session/1_funk-groove1_138_beat_4-4.mid', 'drummer1/eval_session/1_funk-groove1_138_beat_4-4.wav', '27.872308', 'test']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 44\u001b[0m\n\u001b[0;32m     35\u001b[0m data_point \u001b[38;5;241m=\u001b[39m DataPoint(\n\u001b[0;32m     36\u001b[0m     midi_data\u001b[38;5;241m=\u001b[39mmidi_data,\n\u001b[0;32m     37\u001b[0m     audio_file_path\u001b[38;5;241m=\u001b[39maudio_data_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     purpose\u001b[38;5;241m=\u001b[39mline[feature_to_column_idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Play the sample\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mplay_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmidi_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_point\u001b[38;5;241m.\u001b[39mpurpose \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     47\u001b[0m     X_train[train_idx] \u001b[38;5;241m=\u001b[39m data_point\n",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m, in \u001b[0;36mplay_audio\u001b[1;34m(midi_data)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay_audio\u001b[39m(midi_data: MidiFile) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Create output port for playing samples\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mido\u001b[38;5;241m.\u001b[39mopen_output(autoreset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m outport: \n\u001b[1;32m---> 45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmidi_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outport\u001b[38;5;241m.\u001b[39mclosed:\n",
      "File \u001b[1;32mc:\\Users\\mrmar\\Downloads\\Neural Networks\\Project\\NN_Drummer_Beat_Project\\.venv\\Lib\\site-packages\\mido\\midifiles\\midifiles.py:433\u001b[0m, in \u001b[0;36mMidiFile.play\u001b[1;34m(self, meta_messages, now)\u001b[0m\n\u001b[0;32m    430\u001b[0m duration_to_next_event \u001b[38;5;241m=\u001b[39m input_time \u001b[38;5;241m-\u001b[39m playback_time\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m duration_to_next_event \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(duration_to_next_event)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, MetaMessage) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m meta_messages:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Initiate data structures\n",
    "X_train = [0] * 897\n",
    "X_test = [0] * 129\n",
    "X_validation = [0] * 124\n",
    "# y_train = np.zeros(())\n",
    "# y_test = np.zeros(())\n",
    "\n",
    "# Define filename and its path\n",
    "data_filename = \"info.csv\"\n",
    "data_folder_path = Path().cwd() / \"data\"\n",
    "data_path = data_folder_path / data_filename\n",
    "\n",
    "\n",
    "\n",
    "# Open file with data information\n",
    "with data_path.open() as file:\n",
    "    columns = file.readline()\n",
    "    train_idx = 0\n",
    "    test_idx = 0\n",
    "    validation_idx = 0\n",
    "    for i, line in enumerate(file):\n",
    "        # Strip line of new line and split into list\n",
    "        line = line.strip().split(\",\")\n",
    "\n",
    "        # Check\n",
    "        print(line)\n",
    "\n",
    "        # Attach absolute path to midi & audio files\n",
    "        midi_data_path = data_folder_path / line[7]\n",
    "        audio_data_path = data_folder_path / line[8]\n",
    "\n",
    "        # Create custom data point with all info\n",
    "        midi_data = MidiFile(midi_data_path)\n",
    "        features = {i: line[feature_to_column_idx[i]] for i in feature_names}\n",
    "        data_point = DataPoint(\n",
    "            midi_data=midi_data,\n",
    "            audio_file_path=audio_data_path,\n",
    "            midi_file_path=midi_data_path,\n",
    "            features=features,\n",
    "            purpose=line[feature_to_column_idx[\"split\"]]\n",
    "        )\n",
    "\n",
    "        # Play the sample\n",
    "        play_audio(midi_data)\n",
    "\n",
    "        if data_point.purpose == \"train\":\n",
    "            X_train[train_idx] = data_point\n",
    "            train_idx += 1\n",
    "        elif data_point.purpose == \"test\":\n",
    "            X_test[test_idx] = data_point\n",
    "            test_idx += 1\n",
    "        elif data_point.purpose == \"validation\":\n",
    "            X_validation[validation_idx] = data_point\n",
    "            validation_idx += 1\n",
    "\n",
    "        # print(line.strip().split(\",\"))\n",
    "        print(\"Next sample\\n\")\n",
    "        if i == 2: print(\"Breaking\"); break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train, X_test, X_validation, sep=\"\\n\")\n",
    "# print(X_test[0])\n",
    "\n",
    "for i in X_test[:1]:\n",
    "    print(i.purpose, i.features, i.midi_file_path, i.audio_file_path, sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
